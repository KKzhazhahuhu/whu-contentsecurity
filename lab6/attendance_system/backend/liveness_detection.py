import cv2
import numpy as np
import requests
import base64
import dlib
from scipy.spatial import distance as dist
from config import Config
import time


class LivenessDetector:
    def __init__(self):
        self.baidu_access_token = None

        # çœ¨çœ¼æ£€æµ‹ç›¸å…³å‚æ•°
        self.EYE_AR_THRESH = 0.25  # çœ¼ç›é•¿å®½æ¯”é˜ˆå€¼
        self.EYE_AR_CONSEC_FRAMES = 3  # è¿ç»­å¸§æ•°
        self.COUNTER = 0
        self.TOTAL_BLINKS = 0

        # å˜´éƒ¨æ£€æµ‹ç›¸å…³å‚æ•°
        self.MOUTH_AR_THRESH = 0.7  # å˜´éƒ¨é•¿å®½æ¯”é˜ˆå€¼
        self.mouth_opened = False
        self.mouth_open_frames = 0

        # å¤´éƒ¨å§¿æ€ç›¸å…³å‚æ•°
        self.head_poses = []
        self.pose_change_threshold = 15  # è§’åº¦å˜åŒ–é˜ˆå€¼

        # åˆå§‹åŒ–dlibäººè„¸å…³é”®ç‚¹æ£€æµ‹å™¨
        try:
            self.detector = dlib.get_frontal_face_detector()
            # éœ€è¦ä¸‹è½½shape_predictor_68_face_landmarks.datæ–‡ä»¶
            self.predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')
            self.dlib_available = True
            print("dlibåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"è­¦å‘Š: dlibäººè„¸å…³é”®ç‚¹æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.dlib_available = False

        # æ—¶é—´æˆ³è®°å½•
        self.start_time = time.time()

        self.get_baidu_access_token()

    def get_baidu_access_token(self):
        """è·å–ç™¾åº¦APIè®¿é—®ä»¤ç‰Œ"""
        if not Config.BAIDU_API_KEY or not Config.BAIDU_SECRET_KEY:
            print("è­¦å‘Š: ç™¾åº¦APIå¯†é’¥æœªé…ç½®")
            return None

        url = Config.BAIDU_TOKEN_URL
        params = {
            'grant_type': 'client_credentials',
            'client_id': Config.BAIDU_API_KEY,
            'client_secret': Config.BAIDU_SECRET_KEY
        }

        try:
            response = requests.post(url, params=params)
            result = response.json()

            if 'access_token' in result:
                self.baidu_access_token = result['access_token']
                print("ç™¾åº¦APIè®¿é—®ä»¤ç‰Œè·å–æˆåŠŸ")
                return self.baidu_access_token
            else:
                print(f"è·å–ç™¾åº¦è®¿é—®ä»¤ç‰Œå¤±è´¥: {result}")
                return None
        except Exception as e:
            print(f"è¯·æ±‚ç™¾åº¦è®¿é—®ä»¤ç‰Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None

    def image_to_base64(self, image):
        """å°†å›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç """
        _, buffer = cv2.imencode('.jpg', image)
        return base64.b64encode(buffer).decode('utf-8')

    # æ›¿æ¢ä½ çš„ baidu_liveness_detection æ–¹æ³•ä¸ºä»¥ä¸‹ç‰ˆæœ¬ï¼š

    def baidu_liveness_detection(self, image):
        """ä½¿ç”¨ç™¾åº¦APIè¿›è¡Œæ´»ä½“æ£€æµ‹ - å®˜æ–¹æ–‡æ¡£æ ¼å¼"""
        print("=== ç™¾åº¦APIæ´»ä½“æ£€æµ‹ï¼ˆå®˜æ–¹æ ¼å¼ï¼‰===")

        if not self.baidu_access_token:
            print("ç™¾åº¦APIæœªé…ç½®ï¼Œå°è¯•é‡æ–°è·å–token")
            self.get_baidu_access_token()
            if not self.baidu_access_token:
                return 0.0, "ç™¾åº¦APIæœªé…ç½®"

        # ğŸ”§ æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼ŒURLåº”è¯¥æ˜¯è¿™ä¸ª
        request_url = "https://aip.baidubce.com/rest/2.0/face/v3/faceverify"
        request_url = request_url + "?access_token=" + self.baidu_access_token

        print(f"è¯·æ±‚URL: {request_url}")

        # è½¬æ¢å›¾åƒä¸ºbase64
        image_base64 = self.image_to_base64(image)
        print(f"å›¾åƒè½¬æ¢å®Œæˆï¼Œé•¿åº¦: {len(image_base64)}")

        # ğŸ”§ å…³é”®ï¼šæŒ‰ç…§å®˜æ–¹æ–‡æ¡£çš„å‚æ•°æ ¼å¼
        # éœ€è¦æ„å»ºä¸€ä¸ªJSONæ•°ç»„çš„å­—ç¬¦ä¸²ï¼ŒåŒ…å«å›¾ç‰‡ä¿¡æ¯
        params_array = [
            {
                "image": image_base64,
                "image_type": "BASE64",
                "face_field": "age,beauty,expression"  # å¯é€‰å­—æ®µ
            }
        ]

        # ğŸ”§ é‡è¦ï¼šå°†æ•°ç»„è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
        import json
        params = json.dumps(params_array, ensure_ascii=False)

        print(f"å‚æ•°æ ¼å¼: JSONæ•°ç»„å­—ç¬¦ä¸²")
        print(f"å‚æ•°é•¿åº¦: {len(params)}")
        print(f"å‚æ•°ç»“æ„: {[{k: '...' if k == 'image' else v for k, v in params_array[0].items()}]}")

        # ğŸ”§ æŒ‰ç…§å®˜æ–¹æ–‡æ¡£çš„è¯·æ±‚å¤´
        headers = {
            'content-type': 'application/json'  # æ³¨æ„è¿™é‡Œæ˜¯å°å†™çš„content-type
        }

        try:
            print("å‘é€æ´»ä½“æ£€æµ‹è¯·æ±‚...")

            # ğŸ”§ é‡è¦ï¼šä½¿ç”¨dataå‚æ•°è€Œä¸æ˜¯jsonå‚æ•°
            response = requests.post(request_url, data=params, headers=headers, timeout=20)

            print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"å“åº”å†…å®¹: {response.text}")

            # è§£æå“åº”
            result = response.json()
            print(f"è§£æçš„JSON: {result}")

            # æ£€æŸ¥APIè°ƒç”¨æ˜¯å¦æˆåŠŸ
            if result.get('error_code') == 0:
                face_liveness = result.get('result', {}).get('face_liveness', 0.0)

                print(f"âœ… æ´»ä½“æ£€æµ‹æˆåŠŸ")
                print(f"   æ´»ä½“åˆ†æ•°: {face_liveness}")

                return face_liveness, f"ç™¾åº¦æ´»ä½“æ£€æµ‹æˆåŠŸ: {face_liveness:.3f}"

            else:
                # å¤„ç†é”™è¯¯
                error_code = result.get('error_code', 'Unknown')
                error_msg = result.get('error_msg', 'æœªçŸ¥é”™è¯¯')

                print(f"âŒ ç™¾åº¦APIè°ƒç”¨å¤±è´¥:")
                print(f"   é”™è¯¯ä»£ç : {error_code}")
                print(f"   é”™è¯¯ä¿¡æ¯: {error_msg}")

                return 0.0, f"ç™¾åº¦APIé”™è¯¯[{error_code}]: {error_msg}"

        except requests.exceptions.Timeout:
            print("âŒ è¯·æ±‚è¶…æ—¶")
            return 0.0, "ç™¾åº¦APIè¯·æ±‚è¶…æ—¶"

        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            return 0.0, f"ç™¾åº¦APIç½‘ç»œé”™è¯¯: {str(e)}"

        except ValueError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response.text}")
            return 0.0, "ç™¾åº¦APIå“åº”æ ¼å¼é”™è¯¯"

        except Exception as e:
            print(f"âŒ å…¶ä»–å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return 0.0, f"ç™¾åº¦APIè°ƒç”¨å¼‚å¸¸: {str(e)}"
    def eye_aspect_ratio(self, eye):
        """è®¡ç®—çœ¼ç›é•¿å®½æ¯”"""
        # è®¡ç®—å‚ç›´æ–¹å‘çš„çœ¼ç›è·ç¦»
        A = dist.euclidean(eye[1], eye[5])
        B = dist.euclidean(eye[2], eye[4])

        # è®¡ç®—æ°´å¹³æ–¹å‘çš„çœ¼ç›è·ç¦»
        C = dist.euclidean(eye[0], eye[3])

        # è®¡ç®—çœ¼ç›é•¿å®½æ¯”
        ear = (A + B) / (2.0 * C)
        return ear

    def mouth_aspect_ratio(self, mouth):
        """è®¡ç®—å˜´éƒ¨é•¿å®½æ¯”"""
        # è®¡ç®—å‚ç›´æ–¹å‘çš„å˜´éƒ¨è·ç¦»
        A = dist.euclidean(mouth[2], mouth[10])  # 51, 59
        B = dist.euclidean(mouth[4], mouth[8])  # 53, 57

        # è®¡ç®—æ°´å¹³æ–¹å‘çš„å˜´éƒ¨è·ç¦»
        C = dist.euclidean(mouth[0], mouth[6])  # 49, 55

        # è®¡ç®—å˜´éƒ¨é•¿å®½æ¯”
        mar = (A + B) / (2.0 * C)
        return mar

    def blink_detection(self, image):
        """çœ¨çœ¼æ£€æµ‹"""
        if not self.dlib_available:
            return 0.5, "dlibä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤åˆ†æ•°"

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = self.detector(gray)

        if len(faces) == 0:
            return 0.0, "æœªæ£€æµ‹åˆ°äººè„¸"

        for face in faces:
            landmarks = self.predictor(gray, face)
            landmarks_np = np.array([[p.x, p.y] for p in landmarks.parts()])

            # æå–å·¦å³çœ¼çš„å…³é”®ç‚¹
            left_eye = landmarks_np[36:42]
            right_eye = landmarks_np[42:48]

            # è®¡ç®—çœ¼ç›é•¿å®½æ¯”
            left_ear = self.eye_aspect_ratio(left_eye)
            right_ear = self.eye_aspect_ratio(right_eye)
            ear = (left_ear + right_ear) / 2.0

            # æ£€æŸ¥æ˜¯å¦çœ¨çœ¼
            if ear < self.EYE_AR_THRESH:
                self.COUNTER += 1
            else:
                if self.COUNTER >= self.EYE_AR_CONSEC_FRAMES:
                    self.TOTAL_BLINKS += 1
                self.COUNTER = 0

            # è®¡ç®—æ´»ä½“åˆ†æ•°ï¼ˆåŸºäºçœ¨çœ¼æ¬¡æ•°å’Œæ—¶é—´ï¼‰
            elapsed_time = time.time() - self.start_time
            if elapsed_time > 2:  # è‡³å°‘è§‚å¯Ÿ2ç§’
                blink_rate = self.TOTAL_BLINKS / elapsed_time
                # æ­£å¸¸çœ¨çœ¼é¢‘ç‡å¤§çº¦æ¯åˆ†é’Ÿ15-20æ¬¡ï¼Œå³æ¯ç§’0.25-0.33æ¬¡
                if 0.1 <= blink_rate <= 0.5:
                    liveness_score = min(0.9, 0.5 + blink_rate)
                else:
                    liveness_score = 0.3
            else:
                liveness_score = 0.5

            return liveness_score, f"çœ¨çœ¼æ£€æµ‹: {self.TOTAL_BLINKS}æ¬¡çœ¨çœ¼ï¼Œè¯„åˆ†{liveness_score:.2f}"

        return 0.0, "äººè„¸å¤„ç†å¤±è´¥"

    def mouth_detection(self, image):
        """å¼ å˜´æ£€æµ‹"""
        if not self.dlib_available:
            return 0.5, "dlibä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤åˆ†æ•°"

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = self.detector(gray)

        if len(faces) == 0:
            return 0.0, "æœªæ£€æµ‹åˆ°äººè„¸"

        for face in faces:
            landmarks = self.predictor(gray, face)
            landmarks_np = np.array([[p.x, p.y] for p in landmarks.parts()])

            # æå–å˜´éƒ¨å…³é”®ç‚¹ (49-68)
            mouth = landmarks_np[48:68]

            # è®¡ç®—å˜´éƒ¨é•¿å®½æ¯”
            mar = self.mouth_aspect_ratio(mouth)

            # æ£€æŸ¥æ˜¯å¦å¼ å˜´
            if mar > self.MOUTH_AR_THRESH:
                if not self.mouth_opened:
                    self.mouth_opened = True
                    self.mouth_open_frames = 1
                else:
                    self.mouth_open_frames += 1
            else:
                if self.mouth_opened and self.mouth_open_frames >= 3:
                    # æ£€æµ‹åˆ°æœ‰æ•ˆçš„å¼ å˜´åŠ¨ä½œ
                    liveness_score = 0.8
                    return liveness_score, f"æ£€æµ‹åˆ°å¼ å˜´åŠ¨ä½œï¼Œè¯„åˆ†{liveness_score:.2f}"
                self.mouth_opened = False
                self.mouth_open_frames = 0

            # åŸºäºå½“å‰çŠ¶æ€è¿”å›åˆ†æ•°
            if self.mouth_opened:
                return 0.6, "æ­£åœ¨å¼ å˜´"
            else:
                return 0.4, "å˜´éƒ¨é—­åˆ"

        return 0.0, "äººè„¸å¤„ç†å¤±è´¥"

    def head_pose_detection(self, image):
        """å¤´éƒ¨å§¿æ€æ£€æµ‹"""
        if not self.dlib_available:
            return 0.5, "dlibä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤åˆ†æ•°"

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = self.detector(gray)

        if len(faces) == 0:
            return 0.0, "æœªæ£€æµ‹åˆ°äººè„¸"

        for face in faces:
            landmarks = self.predictor(gray, face)
            landmarks_np = np.array([[p.x, p.y] for p in landmarks.parts()])

            # 3Dæ¨¡å‹ç‚¹
            model_points = np.array([
                (0.0, 0.0, 0.0),  # é¼»å°–
                (0.0, -330.0, -65.0),  # ä¸‹å·´
                (-225.0, 170.0, -135.0),  # å·¦çœ¼å·¦è§’
                (225.0, 170.0, -135.0),  # å³çœ¼å³è§’
                (-150.0, -150.0, -125.0),  # å·¦å˜´è§’
                (150.0, -150.0, -125.0)  # å³å˜´è§’
            ])

            # 2Då›¾åƒç‚¹
            image_points = np.array([
                landmarks_np[30],  # é¼»å°–
                landmarks_np[8],  # ä¸‹å·´
                landmarks_np[36],  # å·¦çœ¼å·¦è§’
                landmarks_np[45],  # å³çœ¼å³è§’
                landmarks_np[48],  # å·¦å˜´è§’
                landmarks_np[54]  # å³å˜´è§’
            ], dtype="double")

            # ç›¸æœºå‚æ•°
            size = image.shape
            focal_length = size[1]
            center = (size[1] / 2, size[0] / 2)
            camera_matrix = np.array([
                [focal_length, 0, center[0]],
                [0, focal_length, center[1]],
                [0, 0, 1]
            ], dtype="double")

            dist_coeffs = np.zeros((4, 1))

            # æ±‚è§£PnPé—®é¢˜
            success, rotation_vector, translation_vector = cv2.solvePnP(
                model_points, image_points, camera_matrix, dist_coeffs,
                flags=cv2.SOLVEPNP_ITERATIVE
            )

            if success:
                # å°†æ—‹è½¬å‘é‡è½¬æ¢ä¸ºæ¬§æ‹‰è§’
                rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
                angles = cv2.RQDecomp3x3(rotation_matrix)[0]

                # è®°å½•å¤´éƒ¨å§¿æ€
                self.head_poses.append(angles)

                # ä¿æŒæœ€è¿‘10ä¸ªå§¿æ€è®°å½•
                if len(self.head_poses) > 10:
                    self.head_poses.pop(0)

                # è®¡ç®—å§¿æ€å˜åŒ–
                if len(self.head_poses) >= 2:
                    pose_diff = np.abs(np.array(self.head_poses[-1]) - np.array(self.head_poses[0]))
                    max_diff = np.max(pose_diff)

                    if max_diff > self.pose_change_threshold:
                        liveness_score = min(0.9, 0.5 + max_diff / 100)
                        return liveness_score, f"æ£€æµ‹åˆ°å¤´éƒ¨ç§»åŠ¨: {max_diff:.1f}åº¦ï¼Œè¯„åˆ†{liveness_score:.2f}"
                    else:
                        return 0.4, "å¤´éƒ¨ç›¸å¯¹é™æ­¢"
                else:
                    return 0.5, "æ­£åœ¨åˆ†æå¤´éƒ¨å§¿æ€"

        return 0.0, "å§¿æ€æ£€æµ‹å¤±è´¥"

    def dlib_comprehensive_detection(self, image):
        """dlibç»¼åˆæ´»ä½“æ£€æµ‹ï¼ˆçœ¨çœ¼40% + å¼ å˜´40% + å§¿æ€20%ï¼‰"""
        if not self.dlib_available:
            return 0.0, "dlibä¸å¯ç”¨"

        # è·å–å„é¡¹æ£€æµ‹ç»“æœ
        blink_score, blink_msg = self.blink_detection(image)
        mouth_score, mouth_msg = self.mouth_detection(image)
        pose_score, pose_msg = self.head_pose_detection(image)

        # æŒ‰æƒé‡è®¡ç®—ç»¼åˆåˆ†æ•°
        weights = Config.DLIB_WEIGHTS
        final_score = (
                blink_score * weights['blink'] +
                mouth_score * weights['mouth'] +
                pose_score * weights['pose']
        )

        message = f"dlibç»¼åˆæ£€æµ‹: çœ¨çœ¼{blink_score:.2f}({weights['blink'] * 100}%), å¼ å˜´{mouth_score:.2f}({weights['mouth'] * 100}%), å§¿æ€{pose_score:.2f}({weights['pose'] * 100}%)"

        return final_score, message

    def comprehensive_liveness_detection(self, image, method='combined'):
        """
        ç»¼åˆæ´»ä½“æ£€æµ‹
        methodå¯é€‰å€¼ï¼š
        - 'baidu_only': ä»…ä½¿ç”¨ç™¾åº¦API
        - 'dlib_only': ä»…ä½¿ç”¨dlibæ£€æµ‹ï¼ˆçœ¨çœ¼40%+å¼ å˜´40%+å§¿æ€20%ï¼‰
        - 'combined': ç™¾åº¦API 50% + dlibæ£€æµ‹ 50%
        """
        results = {}
        final_score = 0.0
        messages = []

        print(f"å¼€å§‹æ´»ä½“æ£€æµ‹ï¼Œæ–¹æ³•: {method}")

        if method == 'baidu_only':
            # ä»…ä½¿ç”¨ç™¾åº¦API
            score, msg = self.baidu_liveness_detection(image)
            results['baidu_api'] = {'score': score, 'message': msg}
            final_score = score
            messages.append(f"ç™¾åº¦API: {msg}")

        elif method == 'dlib_only':
            # ä»…ä½¿ç”¨dlibæ£€æµ‹
            score, msg = self.dlib_comprehensive_detection(image)
            results['dlib_detection'] = {'score': score, 'message': msg}
            final_score = score
            messages.append(f"dlibæ£€æµ‹: {msg}")

        elif method == 'combined':
            # ç»¼åˆæ£€æµ‹ï¼šç™¾åº¦API 50% + dlibæ£€æµ‹ 50%
            baidu_score, baidu_msg = self.baidu_liveness_detection(image)
            dlib_score, dlib_msg = self.dlib_comprehensive_detection(image)

            results['baidu_api'] = {'score': baidu_score, 'message': baidu_msg}
            results['dlib_detection'] = {'score': dlib_score, 'message': dlib_msg}

            # 50% - 50% æƒé‡
            final_score = baidu_score * 0.5 + dlib_score * 0.5

            messages.append(f"ç™¾åº¦API(50%): {baidu_msg}")
            messages.append(f"dlibæ£€æµ‹(50%): {dlib_msg}")
            messages.append(f"ç»¼åˆè¯„åˆ†: {final_score:.2f}")

        else:
            return {
                'final_score': 0.0,
                'is_live': False,
                'details': {},
                'message': f'ä¸æ”¯æŒçš„æ£€æµ‹æ–¹æ³•: {method}'
            }

        is_live = final_score >= Config.LIVENESS_THRESHOLD

        print(f"æ´»ä½“æ£€æµ‹å®Œæˆï¼Œæœ€ç»ˆåˆ†æ•°: {final_score:.2f}, æ˜¯å¦ä¸ºæ´»ä½“: {is_live}")

        return {
            'final_score': final_score,
            'is_live': is_live,
            'details': results,
            'message': '; '.join(messages),
            'method': method
        }

    def reset_counters(self):
        """é‡ç½®è®¡æ•°å™¨"""
        self.COUNTER = 0
        self.TOTAL_BLINKS = 0
        self.mouth_opened = False
        self.mouth_open_frames = 0
        self.head_poses = []
        self.start_time = time.time()
        print("æ´»ä½“æ£€æµ‹è®¡æ•°å™¨å·²é‡ç½®")